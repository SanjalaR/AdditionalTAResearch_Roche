{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"new new location with some cols - output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_20116\\1423183361.py:1: DtypeWarning: Columns (17,18,25,40,41,65,69,73,77,78,81,82,85,86,88,89,90,91,92,94,95,96,97,98,99,100,101,102,103,104,105,106,107,116,119,120,122,123,124,126,127,128,130,131,132,134,135,136,138,139,140,142,143,144,146,147,148,150,151,152,154,155,156,158,159,160,162,163,164,166,167,168,170,171,172,174,175,176,178,179,180,182,183,184,186,187,188,190,191,325,326,327,328,329) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"Nppes data_gastro.csv\")\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Nppes data_gastro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Name', 'Fullname', 'NPI', 'Link',\n",
       "       'Specialty', 'Address', 'Phone', 'Website', 'Page',\n",
       "       'Fuzzy matching percentage', 'City', 'State', 'PostalCode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NPI', 'Entity Type Code', 'Replacement NPI',\n",
       "       'Employer Identification Number (EIN)',\n",
       "       'Provider Organization Name (Legal Business Name)', 'Fullname',\n",
       "       'Provider Last Name (Legal Name)', 'Provider First Name',\n",
       "       'Provider Middle Name', 'Provider Name Prefix Text',\n",
       "       ...\n",
       "       'Healthcare Provider Taxonomy Group_7',\n",
       "       'Healthcare Provider Taxonomy Group_8',\n",
       "       'Healthcare Provider Taxonomy Group_9',\n",
       "       'Healthcare Provider Taxonomy Group_10',\n",
       "       'Healthcare Provider Taxonomy Group_11',\n",
       "       'Healthcare Provider Taxonomy Group_12',\n",
       "       'Healthcare Provider Taxonomy Group_13',\n",
       "       'Healthcare Provider Taxonomy Group_14',\n",
       "       'Healthcare Provider Taxonomy Group_15', 'Certification Date'],\n",
       "      dtype='object', length=331)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_match(value, choices, threshold=80):\n",
    "    \"\"\"Find the best fuzzy match for a given value from choices within an NPI group.\"\"\"\n",
    "    if not choices:  # If no choices available for that NPI id, return None\n",
    "        return None\n",
    "    best_match, score = process.extractOne(value, choices)\n",
    "    return (best_match, score) if score >= threshold else (None, score)\n",
    "\n",
    "\n",
    "# Initialize new columns for matched values\n",
    "df1[\"matched_postalcode\"] = None\n",
    "df1[\"postalcode_match_score\"] = 0\n",
    "df1['5dig_postalcode'] = None\n",
    "df1['5dig_match_score'] = 0\n",
    "df1[\"matched_city\"] = None\n",
    "df1[\"city_match_score\"] = 0\n",
    "df1[\"matched_state\"] = None\n",
    "df1[\"state_match_score\"] = 0\n",
    "\n",
    "# Perform fuzzy matching within the same NPI id group\n",
    "for index, row in df1.iterrows():\n",
    "    npi_id = row[\"NPI\"]\n",
    "    \n",
    "    # Filter df2 to only include rows with the same NPI\n",
    "    df2_subset = df2[df2[\"NPI\"] == npi_id]\n",
    "    \n",
    "    # Perform fuzzy matching within this subset\n",
    "    best_postalcode, postalcode_score = fuzzy_match(\n",
    "        str(row[\"PostalCode\"]), \n",
    "        df2_subset[\"Provider Business Mailing Address Postal Code\"].astype(str).tolist() + df2_subset[\"Provider Business Practice Location Address Postal Code\"].astype(str).tolist()\n",
    "    )\n",
    "\n",
    "    df1.at[index, \"matched_postalcode\"] = best_postalcode\n",
    "    df1.at[index, \"postalcode_match_score\"] = postalcode_score\n",
    "\n",
    "    best_postalcode1, postalcode_score1 = fuzzy_match(\n",
    "        str(row[\"PostalCode\"]), \n",
    "        [str(pc)[:5] for pc in df2_subset[\"Provider Business Mailing Address Postal Code\"].astype(str)[:5].tolist()] + \n",
    "        [str(pc)[:5] for pc in df2_subset[\"Provider Business Practice Location Address Postal Code\"].astype(str)[:5].tolist()]\n",
    "    )\n",
    "\n",
    "    df1.at[index, \"5dig_postalcode\"] = best_postalcode1\n",
    "    df1.at[index, \"5dig_match_score\"] = postalcode_score1\n",
    "    \n",
    "    best_city, city_score = fuzzy_match(\n",
    "        str(row[\"City\"]), \n",
    "        df2_subset[\"Provider Business Mailing Address City Name\"].astype(str).tolist() + df2_subset[\"Provider Business Practice Location Address City Name\"].astype(str).tolist()\n",
    "    )\n",
    "    \n",
    "    df1.at[index, \"matched_city\"] = best_city\n",
    "    df1.at[index, \"city_match_score\"] = city_score\n",
    "\n",
    "    best_state, state_score = fuzzy_match(\n",
    "        str(row[\"State\"]), \n",
    "        df2_subset[\"Provider Business Mailing Address State Name\"].astype(str).tolist() + df2_subset[\"Provider Business Practice Location Address State Name\"].astype(str).tolist()\n",
    "    )\n",
    "\n",
    "    df1.at[index, \"matched_state\"] = best_state\n",
    "    df1.at[index, \"state_match_score\"] = state_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Name', 'Fullname', 'NPI', 'Link',\n",
       "       'Specialty', 'Address', 'Phone', 'Website', 'Page',\n",
       "       'Fuzzy matching percentage', 'City', 'State', 'PostalCode',\n",
       "       'matched_postalcode', 'postalcode_match_score', '5dig_postalcode',\n",
       "       '5dig_match_score', 'matched_city', 'city_match_score', 'matched_state',\n",
       "       'state_match_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('new output with some cols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge both dataframes on NPI\n",
    "df_merged = df1.merge(df2, on=\"NPI\", how=\"left\")\n",
    "\n",
    "# Save the merged file\n",
    "df_merged.to_csv(\"new output with all cols.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
